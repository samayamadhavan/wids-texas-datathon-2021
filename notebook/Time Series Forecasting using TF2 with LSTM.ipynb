{"cells":[{"metadata":{},"cell_type":"markdown","source":["# WOMEN IN DATA SCIENCE TEXAS DATATHON\n","\n","## Problem statement\n","\n","*Forecasting hourly electrical load in each zone in the short-term (the next 7 days).*\n","\n","This year's challenge will focus on electricity load forecasting. Load forecasting is the predicting of electrical power required to meet the short or long-term demand. The forecasting helps utility companies plan on their capacity to keep the electricity running in every household and business.\n","\n","You will build models to learn how the electrical load was inferenced by key factors (e.g., weather) using historical data and make the forecast to a near-future period.\n","\n","<img src=\"https://raw.githubusercontent.com/WiDSTexas2021/datathon-code/main/data/ercotWeatherZoneMap.png\" alt=\"weather zone\" width=\"400\"/>\n","\n","### More information - Visit [website](https://widstexas2021.github.io/datathon/)\n","---\n","Authors :\n","  - [Samaya Madhavan, Senior Software Engineer, IBM](https://www.linkedin.com/in/samaya-madhavan/)\n","---\n","\n","This WiDS event series is brought to you by the following WiDS 2021 Texas ambassadors:\n","\n","- <a href=\"https://www.linkedin.com/in/gaby-arellano-bello-8b485052/\" target=\"_blank\">Gaby Arellano Bello</a>, WiDS Dallas\n","- <a href=\"https://www.linkedin.com/in/pushkarkumarjain/\" target=\"_blank\">Pushkar Kumar Jain</a>, WiDS Houston\n","- <a href=\"https://www.linkedin.com/in/samaya-madhavan/\" target=\"_blank\">Samaya Madhavan</a>, WiDS Dallas\n","- <a href=\"https://www.linkedin.com/in/lindabrewstermeffert/\" target=\"_blank\">Linda Brewster Meffert</a>, WiDS San Antonio\n","- <a href=\"https://www.linkedin.com/in/joanneti/\" target=\"_blank\">Jo-Anne Ting</a>, WiDS Houston\n","- <a href=\"https://www.linkedin.com/in/liliana-torres-68009435/\" target=\"_blank\">Liliana Torres</a>, WiDS Dallas\n","- <a href=\"https://www.linkedin.com/in/tailaiwen/\" target=\"_blank\">Tailai Wen</a>, WiDS Dallas"]},{"metadata":{},"cell_type":"markdown","source":["## SESSION 1 - DATA PREPROCESSING USING PYTHON AND PANDAS\n","\n","### What is data preprocessing? \n","\n","Process of converting raw data into useful format.\n","\n","![ML-steps](https://raw.githubusercontent.com/samayamadhavan/datathon/main/assets/images/machine-learning-steps.png)\n","\n"]},{"metadata":{},"cell_type":"markdown","source":["## Content\n","\n","1. Install and import Python libraries\n","1. Process historical hourly electrical load data in each each ERCOT zone\n","1. Process historical tri-hourly weather dataset in major cities across ERCOT zone\n","1. Combine electrical load data and weather data"]},{"metadata":{},"cell_type":"markdown","source":["## 1. Install and import Python libraries"]},{"metadata":{},"cell_type":"markdown","source":["### What is pandas? \n","\n","[pandas](https://pandas.pydata.org/) is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool,\n","built on top of the Python programming language."]},{"metadata":{"scrolled":true},"cell_type":"code","source":["!pip install --upgrade pandas"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["import pandas as pd\n","pd.__version__"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["import os, types\n","import io, requests\n","from datetime import datetime"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## 2. Process historical hourly electrical load data in each each ERCOT zone\n","\n","The load on the grid varies based on a very large number of factors. Some of the most significant are:\n","\n","1. Time of Day: More electricity is used at times when people are most active\n","1. Weather: More electricity is used during the warmer months, due to air-conditioning units\n","\n","### ERCOT Hourly Power Load \n","\n","* ercot_hourly_load.csv: Includes hourly power load in the eight ERCTO weather zones. The most recent few weeks of data is from ERCOT Actual System Load, while earlier data is from ERCOT Load Data Archives.\n","* weather_zone_cities.json lists all Texas cities in each ERCTO weather zone.\n","* weather_zone_counties.json lists all Texas counties in each ERCTO weather zone."]},{"metadata":{},"cell_type":"markdown","source":["### 2.1 Import dataset from github using Pandas\n","\n","This dataset is located on the [GitHub repository](https://github.com/WiDSTexas2021/datathon-code)."]},{"metadata":{},"cell_type":"code","source":["url = \"https://raw.githubusercontent.com/WiDSTexas2021/datathon-code/main/data/ercot_hourly_load.csv\"\n","s=requests.get(url).content\n","ercot_hourly_df =pd.read_csv(io.StringIO(s.decode('utf-8')))"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 2.2 - Data exploration\n","\n"]},{"metadata":{},"cell_type":"code","source":["ercot_hourly_df.columns"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["ercot_hourly_df.head()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["ercot_hourly_df.dtypes"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["ercot_hourly_df['Hour_Ending'].dtype"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["ercot_hourly_describe = ercot_hourly_df.describe()\n","ercot_hourly_describe"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["ercot_hourly_describe.plot.box()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 2.3 Handle missing data"]},{"metadata":{},"cell_type":"code","source":["ercot_hourly_df.isna().any()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["ercot_hourly_df[ercot_hourly_df.isna().any(axis=1)]"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["ercot_hourly_df = ercot_hourly_df.fillna(method='ffill')"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["ercot_hourly_df[ercot_hourly_df.isna().any(axis=1)]"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 2.4 - datetime - change from *offset-aware* to *offset-naive*\n","\n","What is a time series dataset? - Data collected at different point in time over even intervals. \n","\n","*A timezone's offset refers to how many hours the timezone is from Coordinated Universal Time (UTC).*\n","\n","\n"]},{"metadata":{},"cell_type":"code","source":["ercot_hourly_df['Hour_Ending']"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### Example 1 - '2005-01-01 01:00:00-05:00'"]},{"metadata":{},"cell_type":"code","source":["time_type_1 = '2005-01-01 01:00:00-05:00'\n","\n","\n","#parse time string into a time object in a specified format. \n","dt_1 = datetime.strptime(time_type_1, '%Y-%m-%d %H:%M:%S%z')\n","\n","#print time and timezone name\n","print('time before conversion :' ,dt_1) \n","print('time zone in offset-aware format :' ,dt_1.tzname()) \n","print()\n","\n","#convert time into timestamp\n","timestamp_1 = dt_1.timestamp()\n","print('time converted to timestamp : ', timestamp_1)\n","print()\n","\n","date_from_timestamp_1 = datetime.fromtimestamp(timestamp_1)\n","#d = date_timestamp_1.strftime(\"%m/%d/%Y, %H:%M:%S\")\n","print('time after conversion :' ,date_from_timestamp_1)\n","print('time zone in offset-naive format :' ,date_from_timestamp_1.tzname()) \n","\n"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### Example 2 - '2005-01-01 01:00:00-06:00'"]},{"metadata":{},"cell_type":"code","source":["time_type_2 = '2005-01-01 01:00:00-06:00'\n","\n","#parse time string into a time object in a specified format. \n","dt_2 = datetime.strptime(time_type_2, '%Y-%m-%d %H:%M:%S%z')\n","\n","#print time and timezone name\n","print('time before conversion :' ,dt_2) \n","print('time zone in offset-aware format :' ,dt_2.tzname()) \n","print()\n","\n","#convert time into timestamp\n","timestamp_2 = dt_2.timestamp()\n","print('time converted to timestamp : ', timestamp_2)\n","print()\n","\n","date_from_timestamp_2 = datetime.fromtimestamp(timestamp_2)\n","\n","print('time after conversion :' ,date_from_timestamp_2)\n","print('time zone in offset-naive format :' ,date_from_timestamp_2.tzname()) \n","\n"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["ercot_hourly_df['Hour_Ending_Naive'] = ercot_hourly_df['Hour_Ending'].apply(lambda x: datetime.fromtimestamp(datetime.strptime(str(x), '%Y-%m-%d %H:%M:%S%z').timestamp()))\n","#.strftime(\"%m/%d/%Y, %H:%M:%S\")"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["ercot_hourly_df = ercot_hourly_df.drop(['Hour_Ending'],axis=1)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["ercot_hourly_df['Hour_Ending_Naive']"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 2.5 . Index and filter datetime column to match with historical weather dataset "]},{"metadata":{},"cell_type":"code","source":["ercot_hourly_df = ercot_hourly_df.set_index(['Hour_Ending_Naive'])"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["print(len(ercot_hourly_df))"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["starting_timestamp = '2008-07-01 00:00:00'\n","ending_timestamp = ercot_hourly_df.index[-1]\n","print(ending_timestamp)\n","ercot_hourly_df = ercot_hourly_df[pd.Timestamp(starting_timestamp):pd.Timestamp(ending_timestamp)]"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["ercot_hourly_df.head(30)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["print(len(ercot_hourly_df))"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 2.6 Visualize data "]},{"metadata":{},"cell_type":"code","source":["fig, axs = plt.subplots(8)\n","fig.suptitle('ERCOT electricity load - all Texas regions')\n","axs[0].plot(ercot_hourly_df.index,ercot_hourly_df['Coast'])\n","axs[0].set_title(\"Coast\")\n","axs[1].plot(ercot_hourly_df.index,ercot_hourly_df['East'])\n","axs[1].set_title(\"East\")\n","axs[2].plot(ercot_hourly_df.index,ercot_hourly_df['Far West'])\n","axs[2].set_title(\"Far West\")\n","axs[3].plot(ercot_hourly_df.index,ercot_hourly_df['North'])\n","axs[3].set_title(\"North\")\n","axs[4].plot(ercot_hourly_df.index,ercot_hourly_df['North Central'])\n","axs[4].set_title(\"North Central\")\n","axs[5].plot(ercot_hourly_df.index,ercot_hourly_df['South'])\n","axs[5].set_title(\"South\")\n","axs[6].plot(ercot_hourly_df.index,ercot_hourly_df['South Central'])\n","axs[6].set_title(\"South Central\")\n","axs[7].plot(ercot_hourly_df.index,ercot_hourly_df['West'])\n","axs[7].set_title(\"West\")\n"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["ercot_hourly_df.drop(ercot_hourly_df.columns.difference(['Coast']), 1, inplace=True)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":[" ercot_hourly_df.head()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["plt.figure(1)\n","plt.plot(ercot_hourly_df['Coast'])\n","plt.gcf().autofmt_xdate()\n","plt.title('Ercot Electricity Load - Coast')\n","plt.xlabel('Time')\n","plt.ylabel('Load consumed')\n","plt.show()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 2.7 download formated dataset as csv"]},{"metadata":{},"cell_type":"code","source":["ercot_hourly_df.to_csv('ercot_iso_hourly_load.csv', index=True)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## 3. Process historical tri-hourly weather dataset in major cities across ERCOT zone\n","\n","### Access and process weather data\n","\n","* weather_history.csv includes past weather data of 10 cities cross the 8 ECROT weather zones. The data is from World Weather Online and reported every 3 hours starting from July 1, 2008.\n","* weather_forecast.csv includes weather forecast of 10 cities cross the 8 ECROT weather zones. The data is from World Weather Online and forecast every 3 hours in the next 13 days (including today)."]},{"metadata":{},"cell_type":"markdown","source":["### 3.1 Import dataset from github using Pandas"]},{"metadata":{},"cell_type":"code","source":["import os, types\n","import pandas as pd\n","import io, requests\n","\n","url = \"https://raw.githubusercontent.com/WiDSTexas2021/datathon-code/main/data/weather_history.csv\"\n","\n","s=requests.get(url).content\n","weather_history_df =pd.read_csv(io.StringIO(s.decode('utf-8')))\n","\n"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 3.2 data exploration"]},{"metadata":{},"cell_type":"code","source":["weather_history_df.head()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["weather_history_df.columns"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["weather_history_df.dtypes"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["<img src=\"https://raw.githubusercontent.com/WiDSTexas2021/datathon-code/main/data/ercotWeatherZoneMap.png\" alt=\"weather zone\" width=\"500\"/>"]},{"metadata":{},"cell_type":"code","source":["print(weather_history_df['city'].unique())"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 3.3 - Data transformation"]},{"metadata":{"tags":[]},"cell_type":"code","source":["print(weather_history_df['time'].unique())"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["weather_history_df['time'] = weather_history_df['time'].apply(lambda x: str(x).zfill(4))"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["print(weather_history_df['time'].unique())"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["weather_history_df['date_time'] = weather_history_df['date'] + ' ' + weather_history_df['time']\n","weather_history_df['date_time']  = weather_history_df['date_time'].apply(lambda x: datetime.strptime(str(x), \"%Y-%m-%d %H%M\"))"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["weather_history_df = weather_history_df.drop(['date','time'],axis=1)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["weather_history_df['date_time'] = weather_history_df['date_time'].apply(lambda x: datetime.fromtimestamp(x.timestamp()))\n","#2021-05-17 00:00:00"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["weather_history_df.head()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["weather_history_df['date_time']"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 3.4 - Attribute selection"]},{"metadata":{},"cell_type":"code","source":[" weather_history_df.drop(weather_history_df.columns.difference(['date_time','city','tempF','FeelsLikeF']), 1, inplace=True)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["weather_history_df = weather_history_df.set_index(['date_time'])"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["weather_history_df.head()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 3.5 Data filtering"]},{"metadata":{},"cell_type":"code","source":["weather_history_df_Houston = weather_history_df[weather_history_df['city']=='Houston']"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["weather_history_df_Houston.head()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["weather_history_df_Houston = weather_history_df_Houston.resample(\"1H\").mean().ffill()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["weather_history_df_Houston.head(12)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["weather_history_df_Houston.head(-12)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["len(weather_history_df_Houston)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 3.6 Visualize data "]},{"metadata":{},"cell_type":"code","source":["plt.plot(weather_history_df_Houston['tempF'])\n","plt.gcf().autofmt_xdate()\n","plt.title('Weather History')\n","plt.xlabel('Time')\n","plt.ylabel('Temperature(F)')\n","plt.show()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["weather_history_df_Houston.plot(y='tempF')"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 3.7 download formated dataset as csv"]},{"metadata":{},"cell_type":"code","source":["weather_history_df_Houston.to_csv('weather_history.csv', index=True)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## 4. Combine electrical load data and weather data"]},{"metadata":{},"cell_type":"code","source":["coast_electricity_weather_hourly_df = ercot_hourly_df.join(weather_history_df_Houston)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["coast_electricity_weather_hourly_df.head()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["coast_electricity_weather_hourly_df.to_csv('electricity_weather_history.csv', index=True)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["#  Session 2 - Time Series Forecasting using TensorFlow 2 in Python with RNN and LSTMs\n","\n","\n","## What is an Artificial Neural Network?  \n","\n","Neural networks are computational structures that map an input to an output based on a network of highly connected processing elements (neurons).  \n","\n","![ANN](https://developer.ibm.com/developer/default/articles/an-introduction-to-deep-learning/images/deep-neural-network.jpg)\n","\n","\n","\n","<a id=\"top\"></a>\n","### Table of Contents\n","\n","1. [Data exploration - a refresher](#load_libraries)\n","1. [Prepare dataset for model training](#load_data)\n","1. [Build, test and evaluate time series forecasting model using Tensorflow and Keras](#prepare_data)\n","\n"]},{"metadata":{},"cell_type":"markdown","source":["## 1. Data exploration - a refresher"]},{"metadata":{},"cell_type":"markdown","source":["#### We set the datetime field as index to make it easy to combine data from multiple sources. To make data more compatible for model building we first reset the index."]},{"metadata":{},"cell_type":"code","source":["coast_electricity_weather_hourly_df.reset_index(inplace=True)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["coast_electricity_weather_hourly_df.head()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["#### Next we verify that none of the entries in the *Hour_Ending_Naive* coulmn is missing or is repeating"]},{"metadata":{},"cell_type":"code","source":["print('Number of entries within the input dataframe : ',len(coast_electricity_weather_hourly_df))\n","\n","print('Numbr of unique time entries in input dataframe: ',len(pd.unique(coast_electricity_weather_hourly_df['Hour_Ending_Naive'])))"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["#### We then perform a sanity check to understand the range of values that are present within our dataset"]},{"metadata":{},"cell_type":"code","source":["pd.concat([coast_electricity_weather_hourly_df.head(1), coast_electricity_weather_hourly_df.tail(1)])"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["#### By executing the cell below, we understand that the last 30 entries of the dataset contains 6 hours of data from yesterday and 24 hours of data from day before yesterday."]},{"metadata":{},"cell_type":"code","source":["coast_electricity_weather_hourly_df.tail(30)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## 2. Prepare data  for model building"]},{"metadata":{},"cell_type":"markdown","source":["### 2.1 Drop numpy incompatible column - *Hour_Ending_Naive*\n","\n","Since data will be changed back and forth between numpy and pandas, we remove the *Hour_Ending_Naive* column to eliminate any datetime related confusion that may arise."]},{"metadata":{},"cell_type":"code","source":["coast_electricity_weather = coast_electricity_weather_hourly_df.drop(['Hour_Ending_Naive'], axis=1)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 2.2 Split data into training and test set \n","\n","We now split the dataset into training and test sets. "]},{"metadata":{},"cell_type":"markdown","source":["#### We include all entries except the last 30 entries in the training set. "]},{"metadata":{},"cell_type":"code","source":["training_data =  coast_electricity_weather.iloc[:-30]"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["print(len(training_data))"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["#### We will eventually use the last 30 entries for evaluating the model. But we include an extra 24 rows to accomodate for calculating the timesteps. More details on it below."]},{"metadata":{},"cell_type":"code","source":["test_data = coast_electricity_weather.iloc[-54:]"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["print(len(test_data))"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 2.3 Feature scaling\n","\n","Feature scaling is a method used to normalize the range of independent variables or features of data. In data processing, it is also known as data normalization and is generally performed during the data preprocessing step. (source : https://en.wikipedia.org/wiki/Feature_scaling)\n","\n","\n","In this section we use [MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) from the scikit-learn's preprocessing API"]},{"metadata":{},"cell_type":"code","source":["from sklearn.preprocessing import MinMaxScaler\n","min_max_scaler = MinMaxScaler(feature_range=(0,1))"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["training_data_scaled = min_max_scaler.fit_transform(training_data)\n","\n","training_data_scaled = pd.DataFrame(training_data_scaled)\n","\n","print('Value of training data : ' + str(training_data_scaled))"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["test_data_scaled = min_max_scaler.transform(test_data)\n","\n","test_data_scaled = pd.DataFrame(test_data_scaled)\n","\n","print('Value of test data : ' + str(test_data_scaled))"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 2.4 Separate data into dependant and independant variables\n","\n","We now split the training data into X_train to represent the dependent variables and y_train to represent the independent variable"]},{"metadata":{},"cell_type":"code","source":["X_train =  pd.DataFrame(training_data_scaled[[1, 2]])\n","y_train =  pd.DataFrame(training_data_scaled[0])"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["print(X_train.shape, y_train.shape)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["We then repeat the same steps for the test data"]},{"metadata":{},"cell_type":"code","source":["X_test =  pd.DataFrame(test_data_scaled[[1, 2]])\n","y_test =  pd.DataFrame(test_data_scaled[0])\n"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["print(X_test.shape, y_test.shape)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 2.5  Modify shape of train and test sets to include time steps\n","\n","### What is Recurrent Neural Network ?\n","\n","A recurrent neural network (RNN) is a class of neural networks that includes weighted connections within a layer (compared with traditional feed-forward networks, where connects feed only to subsequent layers). Because RNNs include loops, they can store information while processing new input. This memory makes them ideal for processing tasks where prior inputs must be considered (such as time-series data). \n","\n","![RNN](https://developer.ibm.com/developer/default/articles/cc-machine-learning-deep-learning-architectures/images/figure03.png)"]},{"metadata":{},"cell_type":"markdown","source":["#### Let's take a look at an example of data is expanded to include time steps history\n","\n","| Electricity_Load  |\n","| -----:|\n","| 1345 |\n","     |   1456 |\n"," |    1444 |\n","  |    2000 |\n","   |    1245 |\n","   \n","   \n","   Let's assume time_step = 2\n","   \n","   | T1        | T2           | Electricity_Load  |\n","| ------------- |:-------------:| -----:|\n","| NA      | NA | 1345 |\n","|NA      | 1345      |   1456 |\n","| 1345 | 1456     |    1444 |\n","| 1456 | 1444     |    2000 |\n","|1444 | 2000      |    1245 |\n"]},{"metadata":{},"cell_type":"code","source":["import numpy as np\n","\n","def create_dataset(X, y, time_steps=1):\n","    Xs, ys = [], []\n","    for i in range(len(X) - time_steps):\n","        v = X.iloc[i:(i + time_steps)].values\n","        Xs.append(v)\n","        ys.append(y.iloc[i + time_steps])\n","        if(i%10000==0):\n","            print('i = ',i)\n","            print('i + time_steps = ',i+time_steps)\n","        \n","    return np.array(Xs), np.array(ys)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["time_steps = 24\n","\n","# reshape to [samples, time_steps, n_features]\n","\n","X_train_steps, y_train_steps = create_dataset(X_train, y_train, time_steps)\n","\n"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["print(X_train_steps.shape, y_train_steps.shape)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["X_test_steps, y_test_steps = create_dataset(X_test, y_test, time_steps)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["print(X_test.shape, y_test.shape)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["print(X_test_steps.shape, y_test_steps.shape)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## 3. Build, test and evaluate time series forecasting model using Tensorflow and Keras"]},{"metadata":{},"cell_type":"markdown","source":["### What is Long Short Term Memory? \n","\n","The LSTM departed from typical neuron-based neural network architectures and instead introduced the concept of a memory cell. The memory cell can retain its value for a short or long time as a function of its inputs, which allows the cell to remember what’s important and not just its last computed value.\n","\n","The LSTM memory cell contains three gates that control how information flows into or out of the cell. The input gate controls when new information can flow into the memory. The forget gate controls when an existing piece of information is forgotten, allowing the cell to remember new data. Finally, the output gate controls when the information that is contained in the cell is used in the output from the cell. The cell also contains weights, which control each gate. The training algorithm, commonly BPTT, optimizes these weights based on the resulting network output error.\n","\n","![LSTM](https://developer.ibm.com/developer/default/articles/cc-machine-learning-deep-learning-architectures/images/figure04.png)"]},{"metadata":{},"cell_type":"markdown","source":["### 3.1 Import required tensorflow packages\n","\n","### What is TensorFlow? \n","\n","TensorFlow is an open source deep learning framework that was released in late 2015 under the Apache 2.0 license. Since then, it has become one of the most widely adopted deep learning frameworks in the world (going by the number of GitHub projects based on it).\n","\n","![TFVSKS](https://developer.ibm.com/developer/default/articles/compare-deep-learning-frameworks/images/tfvsk.png)\n"]},{"metadata":{},"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import LSTM, Dense\n","from tensorflow.keras.optimizers import Adam"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 3.2 Initialize keras model and LSTM and Dense layer"]},{"metadata":{},"cell_type":"code","source":["model = Sequential()\n","\n","model.add(LSTM(units=12,input_shape=(X_train_steps.shape[1], X_train_steps.shape[2])))\n","\n","model.add(tf.keras.layers.Dense(units=1))\n","\n","model.compile(loss='mean_squared_error',optimizer=tf.keras.optimizers.Adam(0.001))"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 3.3 Fit time series model using training data "]},{"metadata":{},"cell_type":"code","source":["history = model.fit(\n","    X_train_steps[len(X_train_steps)-500:len(X_train_steps),:], y_train_steps[len(y_train_steps)-500:len(y_train_steps)],\n","    epochs=1,\n","    batch_size=200,\n","    validation_split=0.1,\n","    verbose=1,\n","    shuffle=False\n",")"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 3.4 Run predictions on the time series model using test data"]},{"metadata":{},"cell_type":"code","source":["predicted_electricity_load = model.predict(X_test_steps)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["print(predicted_electricity_load)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["#### Notice that the predicted value is scaled to a value between 0 and 1 because of the MinMaxScaler that we applied. To reverse the value to its original scale we need to apply *inverse_transform* on the scaler object. \n","\n","But before that, we need to create a numpy array that is compatible to the original dataset on which the scaler was applied"]},{"metadata":{},"cell_type":"code","source":["predicted_np = np.column_stack( (predicted_electricity_load , np.ones((30,1)), np.ones((30,1)) ))"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["print(predicted_np.shape)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["predicted_electricity_load_inverse = min_max_scaler.inverse_transform(predicted_np)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["predicted_electricity_load_inverse"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["#### We repeat the same steps to recover the original electricity load consumption of the test data"]},{"metadata":{},"cell_type":"code","source":["actual_np = np.column_stack( (y_test_steps , np.ones((30,1)), np.ones((30,1)) ) )"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["actual_electricity_load_inverse = min_max_scaler.inverse_transform(actual_np)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["actual_electricity_load_inverse"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 3.5 Evaluate model performance by visualizing results\n","\n","We will now visualize the model using matplotlib to analyze model performance. Closer the red line is to the green line, better the model performance. "]},{"metadata":{},"cell_type":"code","source":["plt.plot(actual_electricity_load_inverse[0:24,0], color='green', label = 'Real electricity consumption')\n","plt.plot(predicted_electricity_load_inverse[0:24,0], color='red', label = 'Predicted electricity consumption')\n","plt.title('Electricity consumption for 24 hours in Coast region')\n","plt.xlabel('Time')\n","plt.ylabel('Electricity consumption')\n","plt.show()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## Related content \n","\n","1. [Data analysis in Python using pandas](https://developer.ibm.com/tutorials/data-analysis-in-python-using-pandas/)\n","1. [Get started with machine learning](https://developer.ibm.com/learningpaths/learning-path-machine-learning-for-developers/)\n","1. [Get started with deep learning](https://developer.ibm.com/series/get-started-with-deep-learning/)"]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3.7","language":"python"},"metadata":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}